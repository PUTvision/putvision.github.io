---
layout: single
title: "EASi Workshop at ECAI-2025 - Explainable AI (XAI) for space"
author: [aszkowski-przemyslaw, kraft-marek]
modified: 2025-10-30
tags: [space, xai, ai, conference, workshop]
category: [conference]
teaser: "/assets/images/posts/2025/11/easi_thumb.webp"
---

<p align="center">
    <img src="/assets/images/posts/2025/11/ecai.webp" height="300px"/>
</p>

Between 25–30 October 2025 we co-organized the EASi workshop (Explainable AI in Space) and took part in the ECAI 2025 conference in Bologna. ECAI is the 28th European Conference on Artificial Intelligence, bringing together researchers, practitioners and innovators in AI through keynotes, paper sessions, workshops and tutorials.

The EASi workshop took place as part of ECAI, under the theme HYPERVIEW2. It was organised by Poznan University of Technology, KP Labs, the ESA Φ-Lab and Warsaw University of Technology. The workshop combines a challenge (HYPERVIEW2) and a call for papers, allowing participants to either compete in the challenge, publish a paper, or do both.
The HYPERVIEW2 Challenge focused on advancing explainable AI methods for Earth observation through the analysis of multi and hyper hyperspectral satellite and airborne data. This second edition of the challenge encouraged participants to design models capable not only of achieving high accuracy in data interpretation but also of providing transparent and interpretable reasoning behind their outputs.
More details can be found at workshop webpage - https://ai4eo.eu/portfolio/easi-workshop-hyperview2/

<p align="center">
    <img src="/assets/images/posts/2025/11/easi_panel.webp" height="300px"/>
</p>

Explainable AI in space matters because AI is increasingly used for mission-critical tasks such as satellite operations, Earth observation, and environmental monitoring. Without transparency or interpretability, decisions made by AI systems might lack accountability or trustworthiness — especially in high-stakes or safety-critical scenarios.By promoting explainability, the workshop helps ensure that AI can be audited, understood by human operators, and aligned with ethical and safety requirements in space-related contexts.
